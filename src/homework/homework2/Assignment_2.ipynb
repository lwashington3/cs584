{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a39a74f-e60d-430d-a378-6e1948d1376f",
   "metadata": {},
   "source": [
    "## Assignment 2 (70 marks)\n",
    "#### =====================================================================================================\n",
    "### Deadline: 10/11 11:59 pm\n",
    "#### ====================================================================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de21b2f3-2ca0-4730-aee8-50caf034dd6a",
   "metadata": {},
   "source": [
    "### Problem 1: Classification (35 marks)\n",
    "\n",
    "`lab02_dataset_1.xlsx` contains 10,302 observations on various vehicles. You will use the observations in this dataset to train models that predict the usage of a vehicle. The input features which will be used for your training are *AGE, TRAVTIME, CAR_TYPE, OCCUPATION, EDUCATION* and your output label is the binary class *CAR_USE*, whose values are *Private* and *Commercial*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7780c2-ba6a-4b91-9d85-deeed05ae60c",
   "metadata": {},
   "source": [
    "### 1.a (2 marks)\n",
    "For the 5 input features, drop any rows with missing values. Output the new length of the training dataset after you drop the missing values among the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f20e5b1-e8ba-4b32-bd45-3221b734acf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5523599e-b64b-4ee9-8db7-44854ec891f9",
   "metadata": {},
   "source": [
    "### 1.b (6 marks)\n",
    "We want to encode categorical features as an integer array. Look up which sklearn function will allow you to do that and apply that on the input features. Also, remember to standardize your encoded features using `fit_transform` to create your final dataset. Finally, perform a 80-20 split on your dataset (80% for training, 20% for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc8619c-ab71-4d30-b864-b6eb69ecb715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f89a1ca-27fa-4a32-88c3-0550c2f6adc1",
   "metadata": {},
   "source": [
    "### 1.c (6 marks)\n",
    "\n",
    "i. Train a logistic regression model using `LogisticRegression`.\n",
    "\n",
    "ii. Train a naive bayes model using `CategoricalNB` with a laplace smoothing of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48b1f9e-7c0b-426a-9f92-581b0efb1eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fed0a941-2e71-48fd-a78f-c0c6d902981f",
   "metadata": {},
   "source": [
    "### 1.d (6 marks)\n",
    "Compute and output the `accuracy_score` for both the classification models you learned on the testing partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286fac29-5fb8-4af3-834a-d515364e4718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b8bc236-5aea-4d3a-8d57-77429e747b2a",
   "metadata": {},
   "source": [
    "### 1.e (6 marks)\n",
    "\n",
    "Let us study a few fictitious persons (test cases). Use the `CategoricalNB` model for this task.\n",
    "\n",
    "Person 1, whose age is 45, has a travel time of 46, works in a Manager occupation, has an education level of Masters, and owns a Minivan.\n",
    "\n",
    "Person 2, whose age is 51, has a travel time of 32, works in a Clerical occupation, has an education level of Below High Sc, and owns a Pickup.\n",
    "\n",
    "Person 3, whose age is 25, has a travel time of 14, works in a Blue Collar occupation, has an education level of High School, and owns a SUV.\n",
    "\n",
    "Display a datraframe that captures all the above information, alongwith two additional columns which will display the Car Use probabilities of these three people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a501aa-6101-4ce1-9acb-d282f05a819c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50ac8ad5-b7fe-4a57-9678-9d986969d512",
   "metadata": {},
   "source": [
    "### 1.f (5 marks)\n",
    "Generate a histogram of the predicted probabilities of *CAR_USE = Private* using the `CategoricalNB` model.  The bin width is 0.05.  The vertical axis is the proportion of all the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb30136-9c17-4892-8038-db04fdb33eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "188f77ae-d565-4da0-8a6f-0ba907dd4402",
   "metadata": {},
   "source": [
    "### 1.g (4 marks)\n",
    "Using a classification threshold of 0.6 i.e., the class with a probability >= 0.6 is the correct output, what is the misclassification rate (computed on all the observations) of the `CategoricalNB` model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d195f58e-87bc-4e90-a748-e8c54e665283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65a55dfe-8178-44bf-a380-ec22cbaf5e41",
   "metadata": {},
   "source": [
    "### Problem 2: Linear Regression (20 marks)\n",
    "\n",
    "`lab02_dataset_2.csv` contains 238 observations on customer purchase history. You will use the observations in this dataset to train models that predict the loyalty score of a customer. The input features which will be used for your training are *age, annual_income, purchase_amount, purchase_frequency* and your output label is *loyalty_score*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a99a12-5f38-4d52-872e-5e6314353751",
   "metadata": {},
   "source": [
    "### 2.a (2 marks)\n",
    "Use the `MinMaxScaler` to transform the input features. Then apply a train-test split of 80-20 to generate the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cba4206-de81-4d80-a66d-fc93d71329d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e89f664-c9b3-461d-be06-579bb070ce4f",
   "metadata": {},
   "source": [
    "### 2.b (10 marks)\n",
    "Complete the empty functions inside the `myLinearRegression` class so that you can be perform linear regression without using sklearn. You are free to add additional helper functions if you need them. We will use a learning rate of 0.01 and 1000 training iterations for the learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627d5c5d-c4fe-4b22-afad-c9e1d41e36a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLinearRegression():\n",
    "    def __init__(self, learning_rate, iterations):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "\n",
    "    # Model fitting. Initialize all the weights and bias with 0.0. Update them using gradient descent.\n",
    "    # Use the linear regression formulation as shown in the slides: W = W - (learning_rate/n)*sum[X(W.X - Y)]\n",
    "    def fit(self, X, Y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pass\n",
    "\n",
    "model = myLinearRegression(learning_rate = 0.01, iterations = 1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04ade3d-145f-4763-8770-c714896c7e49",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### 2.c (2 marks)\n",
    "Compute and output the `mean_squared_error` between the prediction and the true test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6312fe8c-9fef-4628-b314-bdb7b908dcec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57686bdc-99e9-458e-a4c9-cd532b8483e2",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### 2.d (6 marks)\n",
    "Now using sklearn `SGDRegressor` and `LinearRegression` learn two corresponding models using the same training set and test it on the test set. Output the `mean_squared_error` of both the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f2d49-f28c-4d51-ba2a-12bd5a0ea41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ae60954-31d2-44a5-b385-8fe16f2a5dd8",
   "metadata": {},
   "source": [
    "### Problem 3: Regularization (15 marks)\n",
    "\n",
    "`lab02_dataset_3.csv` has 6,435 observations pertaining to Walmart sales and employment. The input features for your training task are *Weekly_Sales, Holiday_Flag, Temperature, Fuel_Price, CPI* and the output label is *Unemployment*. For this problem, you will be using regression with regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fcd24e-d1fa-436c-8848-b24f5432d562",
   "metadata": {},
   "source": [
    "### 3.a (3 marks)\n",
    "Use the sklearn `StandardScaler` to transform the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e7a22-0ec0-49fa-a28d-effa557310be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3471da32-46bc-425a-b6fc-1867099251a8",
   "metadata": {},
   "source": [
    "### 3.b (4 marks)\n",
    "\n",
    "Use sklearn `ridge_regression` with `alpha=1.5` to compute the coefficients of the linear regression model. What are the two most important features (feature with the largest positive/negative weights are the most relevant)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a1ad59-4b26-4d49-a1e9-ee32d7d01900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "536056ec-1842-4220-bc77-5b4f9933eb9f",
   "metadata": {},
   "source": [
    "Two most important features: ____________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0281dca7-1552-4cf3-aa24-99af38ef60ce",
   "metadata": {},
   "source": [
    "### 3.c (4 marks)\n",
    "Compute the Pearson correlation coefficient between the input features and the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e6a53-181d-461e-9485-675b4cb8e0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1574493-c5f0-4f64-ba97-8795b5178c26",
   "metadata": {},
   "source": [
    "The correlation coefficient aligns well with the feature importance as seen in 3.b. Yes or No? __________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58190b77-10c5-4f69-97ae-01eb619f7b76",
   "metadata": {},
   "source": [
    "### 3.d (4 marks)\n",
    "Create a correlation heatmap using the input features and the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630980d7-7e2f-4a51-87f5-6851f53b348b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
